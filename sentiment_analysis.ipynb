{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 20:46:01.458393: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-15 20:46:02.623672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 20:46:02.623831: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 20:46:02.623838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datasets\n",
    "import torch.nn as nn\n",
    "import data_process as dp\n",
    "import torchtext\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wzoruję się na publikacji [SentiMATE: Learning to play Chess through Natural Language Processing](./papers/SentiMate.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane\n",
    "Ruchy z komentarzami są wyciągnięte z gier z [gameknot.com](https://gameknot.com/list_annotated.pl?u=all), baza danych jest za duża na GitHuba, wrzuciłem ją na [dysk Google](https://drive.google.com/file/d/1JzrTIk67jJ4dd_Ak1y71mRd9rWuJij2f/view?usp=sharing)\n",
    "\n",
    "* Ruchom z oznaczeniami `?` lub `??` na początku komentarza dałem `sentiment=0`. Ruchom z `!` lub `!!` - `sentiment=1`. Te komentarze mają `auto_sentiment=1`\n",
    "* Do tego kilka komentarzy oceniłem ręcznie (pomijalna liczba).\n",
    "* `sentiment=2` oznacza, że komentarz nie odnosi się do jakości ruchu, na tą chwilę oceniłem tak tylko kilka komentarzy. W tej publikacji mieli klasyfikator Quality/Non-quality, u mnie tego nie ma, przynajmniej na tę chwilę.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>position</th>\n",
       "      <th>move</th>\n",
       "      <th>comment</th>\n",
       "      <th>halfmove_number</th>\n",
       "      <th>game_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>auto_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...</td>\n",
       "      <td>e2e4</td>\n",
       "      <td>This is my first gameknot game against someone...</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>b1c3</td>\n",
       "      <td>I've been playing the Vienna Gambit as white, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rnbqkbnr/pppp1ppp/8/4p3/4P3/2N5/PPPP1PPP/R1BQK...</td>\n",
       "      <td>f8c5</td>\n",
       "      <td>Minor disappointment.</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>r1bqk2r/pppp1ppp/2n2n2/2b1p3/2B1P3/2NP4/PPP2PP...</td>\n",
       "      <td>f2f4</td>\n",
       "      <td>My idea here is to expand on the kingside, dri...</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>r1bqk2r/ppp2ppp/3p1n2/n1b1pP2/2B1P3/2NP4/PPP3P...</td>\n",
       "      <td>d1f3</td>\n",
       "      <td>Maybe this isn't the greatest plan, since with...</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326634</th>\n",
       "      <td>326634</td>\n",
       "      <td>rnb5/p2p1P1N/7p/1pR5/6P1/4k3/2P1B3/3Q1RK1 b - ...</td>\n",
       "      <td>b5b4</td>\n",
       "      <td>Pawn</td>\n",
       "      <td>86</td>\n",
       "      <td>70387</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326635</th>\n",
       "      <td>326635</td>\n",
       "      <td>rnb5/p2p1P1N/7p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 w -...</td>\n",
       "      <td>f7f8q</td>\n",
       "      <td>Check mate in two moves</td>\n",
       "      <td>87</td>\n",
       "      <td>70387</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326636</th>\n",
       "      <td>326636</td>\n",
       "      <td>rnb2Q2/p2p3N/7p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 b -...</td>\n",
       "      <td>d7d6</td>\n",
       "      <td>Pawn</td>\n",
       "      <td>88</td>\n",
       "      <td>70387</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326637</th>\n",
       "      <td>326637</td>\n",
       "      <td>rnb2Q2/p6N/3p3p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 w -...</td>\n",
       "      <td>f8e8</td>\n",
       "      <td>Check</td>\n",
       "      <td>89</td>\n",
       "      <td>70387</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326638</th>\n",
       "      <td>326638</td>\n",
       "      <td>rnb1Q3/p6N/3p3p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 b -...</td>\n",
       "      <td>c8e6</td>\n",
       "      <td>Bishop</td>\n",
       "      <td>90</td>\n",
       "      <td>70387</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326639 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                           position   move  \\\n",
       "0            0  rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w ...   e2e4   \n",
       "1            1  rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...   b1c3   \n",
       "2            2  rnbqkbnr/pppp1ppp/8/4p3/4P3/2N5/PPPP1PPP/R1BQK...   f8c5   \n",
       "3            3  r1bqk2r/pppp1ppp/2n2n2/2b1p3/2B1P3/2NP4/PPP2PP...   f2f4   \n",
       "4            4  r1bqk2r/ppp2ppp/3p1n2/n1b1pP2/2B1P3/2NP4/PPP3P...   d1f3   \n",
       "...        ...                                                ...    ...   \n",
       "326634  326634  rnb5/p2p1P1N/7p/1pR5/6P1/4k3/2P1B3/3Q1RK1 b - ...   b5b4   \n",
       "326635  326635  rnb5/p2p1P1N/7p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 w -...  f7f8q   \n",
       "326636  326636  rnb2Q2/p2p3N/7p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 b -...   d7d6   \n",
       "326637  326637  rnb2Q2/p6N/3p3p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 w -...   f8e8   \n",
       "326638  326638  rnb1Q3/p6N/3p3p/2R5/1p4P1/4k3/2P1B3/3Q1RK1 b -...   c8e6   \n",
       "\n",
       "                                                  comment  halfmove_number  \\\n",
       "0       This is my first gameknot game against someone...                1   \n",
       "1       I've been playing the Vienna Gambit as white, ...                3   \n",
       "2                                   Minor disappointment.                4   \n",
       "3       My idea here is to expand on the kingside, dri...                9   \n",
       "4       Maybe this isn't the greatest plan, since with...               13   \n",
       "...                                                   ...              ...   \n",
       "326634                                               Pawn               86   \n",
       "326635                            Check mate in two moves               87   \n",
       "326636                                               Pawn               88   \n",
       "326637                                              Check               89   \n",
       "326638                                             Bishop               90   \n",
       "\n",
       "        game_id  sentiment  auto_sentiment  \n",
       "0            44          2               0  \n",
       "1            44         -1               0  \n",
       "2            44         -1               0  \n",
       "3            44         -1               0  \n",
       "4            44          0               0  \n",
       "...         ...        ...             ...  \n",
       "326634    70387         -1               0  \n",
       "326635    70387         -1               0  \n",
       "326636    70387         -1               0  \n",
       "326637    70387         -1               0  \n",
       "326638    70387         -1               0  \n",
       "\n",
       "[326639 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df = datasets.load_sql_to_df(\"SELECT * FROM english_annotated_moves\", \"./chess.db\")\n",
    "moves_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Używam gotowych embeddingów, preprocessing wygląda tak:\n",
    "\n",
    "1. Wzięcie komentarzy z `sentiment` = 0 lub 1\n",
    "2. Usunięcie z komentarzy notacji szachowej i części interpuncji\n",
    "3. Podział na tokeny z użyciem [Spacy](https://spacy.io/)\n",
    "4. Usunięcie tokenów, które nie mają embeddingów\n",
    "\n",
    "Można to znaleźć w pliku [data_process.py](./data_process.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embbedings = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n",
    "datasets.add_padding_vector_to_embeddings(glove_embbedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[maybe, this, be, not, the, great, plan, since...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[?, too, slow, maybe, .]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[?, this, allow, a, combination, by, white, .,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[!, !, brilliant, move, it, give, black, the, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[!, !, this, move, be, really, fantastic, ., m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>[in, hindsight, be, need, to, get, my, king, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>[keep, black, alive]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>[time, remain, minute, .]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>[black, be, win, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>[lose, move, ?]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18857 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  sentiment\n",
       "0      [maybe, this, be, not, the, great, plan, since...          0\n",
       "1                               [?, too, slow, maybe, .]          0\n",
       "2      [?, this, allow, a, combination, by, white, .,...          0\n",
       "3      [!, !, brilliant, move, it, give, black, the, ...          1\n",
       "4      [!, !, this, move, be, really, fantastic, ., m...          1\n",
       "...                                                  ...        ...\n",
       "19864  [in, hindsight, be, need, to, get, my, king, t...          0\n",
       "19865                               [keep, black, alive]          0\n",
       "19866                          [time, remain, minute, .]          0\n",
       "19867                                [black, be, win, .]          1\n",
       "19868                                    [lose, move, ?]          0\n",
       "\n",
       "[18857 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df = dp.prepare_data_for_sentiment_analysis_training(moves_df, glove_embbedings.stoi)\n",
    "moves_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Warstwa `embedding` jest nietrenowana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer\n",
    "\n",
    "class SentimentAnalysisLSTM(nn.Module):\n",
    "    def __init__(self, embeddings: torchtext.vocab.Vectors, hidden_dim, num_layers = 2, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = create_embedding_layer(embeddings.vectors, non_trainable=True)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embeddings.dim, hidden_size=hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        lstm_output, _ = self.lstm(embedded)\n",
    "        last_lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        logits = self.fc(last_lstm_output)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>[?, this, do, not, protect, against, and, afte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>[?, this, simply, give, control, of, the, squa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>[?, ?, but, with, this, capture, memory, techn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14827</th>\n",
       "      <td>[white, have, now, achieve, his, opening, obje...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18311</th>\n",
       "      <td>[fatal, !]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>[?, ?, allow, thing, to, end, soon, than, expect]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13427</th>\n",
       "      <td>[the, knight, on, protect, the, square, ., her...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>[do, not, know, if, this, move, be, really, go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>[?, be, so, hope, he, would, do, that, ., now,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>[the, final, blunder, ..., to, be, honest, do,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  sentiment\n",
       "7583   [?, this, do, not, protect, against, and, afte...          0\n",
       "5697   [?, this, simply, give, control, of, the, squa...          0\n",
       "8436   [?, ?, but, with, this, capture, memory, techn...          0\n",
       "14827  [white, have, now, achieve, his, opening, obje...          1\n",
       "18311                                         [fatal, !]          0\n",
       "...                                                  ...        ...\n",
       "6838   [?, ?, allow, thing, to, end, soon, than, expect]          0\n",
       "13427  [the, knight, on, protect, the, square, ., her...          1\n",
       "14130  [do, not, know, if, this, move, be, really, go...          1\n",
       "1177   [?, be, so, hope, he, would, do, that, ., now,...          0\n",
       "14080  [the, final, blunder, ..., to, be, honest, do,...          0\n",
       "\n",
       "[17914 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15462</th>\n",
       "      <td>[this, do, not, protect, the, n., it, be, nece...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>[or, would, have, be, well, be, an, option, bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>[?, ?, a, terrible, error, .]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>[?, white, have, such, a, strong, possibility,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13289</th>\n",
       "      <td>[[, maybe, even, !, !, ], one, of, my, well, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>[this, move, look, like, a, good, develop, mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>[!, calculate, to, win, the, pin, pick, up, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16637</th>\n",
       "      <td>[wow, a, horrible, blunder, and, immediately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16536</th>\n",
       "      <td>[now, really, win, a, pawn, .]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8884</th>\n",
       "      <td>[be, correct, ., if, now, will, lose, the, adv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  sentiment\n",
       "15462  [this, do, not, protect, the, n., it, be, nece...          0\n",
       "9568   [or, would, have, be, well, be, an, option, bu...          0\n",
       "6219                       [?, ?, a, terrible, error, .]          0\n",
       "648    [?, white, have, such, a, strong, possibility,...          0\n",
       "13289  [[, maybe, even, !, !, ], one, of, my, well, m...          1\n",
       "...                                                  ...        ...\n",
       "10938  [this, move, look, like, a, good, develop, mov...          0\n",
       "4310   [!, calculate, to, win, the, pin, pick, up, th...          1\n",
       "16637  [wow, a, horrible, blunder, and, immediately, ...          0\n",
       "16536                     [now, really, win, a, pawn, .]          0\n",
       "8884   [be, correct, ., if, now, will, lose, the, adv...          0\n",
       "\n",
       "[943 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(moves_df, test_size=0.05)\n",
    "display(train_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.PretrainedEmbeddingsIndicesDataset(train_df, glove_embbedings, random_state=1)\n",
    "test_dataset = datasets.PretrainedEmbeddingsIndicesDataset(test_df, glove_embbedings, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Długość komentarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [len(x) for x,_ in train_dataset]\n",
    "plt.hist(lengths, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    inputs = [item[0] for item in data]\n",
    "    targets = [item[1] for item in data]\n",
    "\n",
    "    input_batch = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    target_batch = torch.stack(targets)\n",
    "\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, num_epochs = 10):\n",
    "    size = len(dataloader.dataset)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentAnalysisLSTM(embeddings=glove_embbedings, hidden_dim=128)\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/50\n",
      "loss: 0.706096  [   32/17914]\n",
      "loss: 0.340999  [ 3232/17914]\n",
      "loss: 0.424385  [ 6432/17914]\n",
      "loss: 0.432129  [ 9632/17914]\n",
      "loss: 0.244874  [12832/17914]\n",
      "loss: 0.173310  [16032/17914]\n",
      "--------------------------\n",
      "epoch 2/50\n",
      "loss: 0.466663  [   32/17914]\n",
      "loss: 0.246941  [ 3232/17914]\n",
      "loss: 0.422193  [ 6432/17914]\n",
      "loss: 0.377362  [ 9632/17914]\n",
      "loss: 0.262325  [12832/17914]\n",
      "loss: 0.226755  [16032/17914]\n",
      "--------------------------\n",
      "epoch 3/50\n",
      "loss: 0.353108  [   32/17914]\n",
      "loss: 0.247966  [ 3232/17914]\n",
      "loss: 0.425609  [ 6432/17914]\n",
      "loss: 0.338204  [ 9632/17914]\n",
      "loss: 0.168835  [12832/17914]\n",
      "loss: 0.263822  [16032/17914]\n",
      "--------------------------\n",
      "epoch 4/50\n",
      "loss: 0.334668  [   32/17914]\n",
      "loss: 0.275556  [ 3232/17914]\n",
      "loss: 0.405290  [ 6432/17914]\n",
      "loss: 0.309720  [ 9632/17914]\n",
      "loss: 0.355301  [12832/17914]\n",
      "loss: 0.236502  [16032/17914]\n",
      "--------------------------\n",
      "epoch 5/50\n",
      "loss: 0.301852  [   32/17914]\n",
      "loss: 0.278560  [ 3232/17914]\n",
      "loss: 0.386353  [ 6432/17914]\n",
      "loss: 0.328328  [ 9632/17914]\n",
      "loss: 0.138207  [12832/17914]\n",
      "loss: 0.217811  [16032/17914]\n",
      "--------------------------\n",
      "epoch 6/50\n",
      "loss: 0.263986  [   32/17914]\n",
      "loss: 0.267133  [ 3232/17914]\n",
      "loss: 0.249180  [ 6432/17914]\n",
      "loss: 0.319248  [ 9632/17914]\n",
      "loss: 0.147824  [12832/17914]\n",
      "loss: 0.235868  [16032/17914]\n",
      "--------------------------\n",
      "epoch 7/50\n",
      "loss: 0.256027  [   32/17914]\n",
      "loss: 0.261514  [ 3232/17914]\n",
      "loss: 0.252457  [ 6432/17914]\n",
      "loss: 0.293258  [ 9632/17914]\n",
      "loss: 0.128039  [12832/17914]\n",
      "loss: 0.216743  [16032/17914]\n",
      "--------------------------\n",
      "epoch 8/50\n",
      "loss: 0.244191  [   32/17914]\n",
      "loss: 0.292170  [ 3232/17914]\n",
      "loss: 0.260888  [ 6432/17914]\n",
      "loss: 0.309369  [ 9632/17914]\n",
      "loss: 0.150154  [12832/17914]\n",
      "loss: 0.197063  [16032/17914]\n",
      "--------------------------\n",
      "epoch 9/50\n",
      "loss: 0.238350  [   32/17914]\n",
      "loss: 0.301192  [ 3232/17914]\n",
      "loss: 0.262115  [ 6432/17914]\n",
      "loss: 0.230103  [ 9632/17914]\n",
      "loss: 0.117542  [12832/17914]\n",
      "loss: 0.253448  [16032/17914]\n",
      "--------------------------\n",
      "epoch 10/50\n",
      "loss: 0.193822  [   32/17914]\n",
      "loss: 0.307188  [ 3232/17914]\n",
      "loss: 0.235345  [ 6432/17914]\n",
      "loss: 0.241373  [ 9632/17914]\n",
      "loss: 0.109744  [12832/17914]\n",
      "loss: 0.243050  [16032/17914]\n",
      "--------------------------\n",
      "epoch 11/50\n",
      "loss: 0.224271  [   32/17914]\n",
      "loss: 0.283094  [ 3232/17914]\n",
      "loss: 0.250955  [ 6432/17914]\n",
      "loss: 0.191167  [ 9632/17914]\n",
      "loss: 0.101203  [12832/17914]\n",
      "loss: 0.261880  [16032/17914]\n",
      "--------------------------\n",
      "epoch 12/50\n",
      "loss: 0.210482  [   32/17914]\n",
      "loss: 0.288755  [ 3232/17914]\n",
      "loss: 0.180004  [ 6432/17914]\n",
      "loss: 0.175310  [ 9632/17914]\n",
      "loss: 0.132051  [12832/17914]\n",
      "loss: 0.156297  [16032/17914]\n",
      "--------------------------\n",
      "epoch 13/50\n",
      "loss: 0.185356  [   32/17914]\n",
      "loss: 0.319789  [ 3232/17914]\n",
      "loss: 0.244670  [ 6432/17914]\n",
      "loss: 0.174499  [ 9632/17914]\n",
      "loss: 0.072979  [12832/17914]\n",
      "loss: 0.190675  [16032/17914]\n",
      "--------------------------\n",
      "epoch 14/50\n",
      "loss: 0.143344  [   32/17914]\n",
      "loss: 0.251923  [ 3232/17914]\n",
      "loss: 0.289596  [ 6432/17914]\n",
      "loss: 0.129063  [ 9632/17914]\n",
      "loss: 0.102069  [12832/17914]\n",
      "loss: 0.156448  [16032/17914]\n",
      "--------------------------\n",
      "epoch 15/50\n",
      "loss: 0.121947  [   32/17914]\n",
      "loss: 0.276693  [ 3232/17914]\n",
      "loss: 0.470921  [ 6432/17914]\n",
      "loss: 0.101952  [ 9632/17914]\n",
      "loss: 0.073830  [12832/17914]\n",
      "loss: 0.111640  [16032/17914]\n",
      "--------------------------\n",
      "epoch 16/50\n",
      "loss: 0.115177  [   32/17914]\n",
      "loss: 0.221915  [ 3232/17914]\n",
      "loss: 0.281970  [ 6432/17914]\n",
      "loss: 0.079323  [ 9632/17914]\n",
      "loss: 0.052101  [12832/17914]\n",
      "loss: 0.122291  [16032/17914]\n",
      "--------------------------\n",
      "epoch 17/50\n",
      "loss: 0.119868  [   32/17914]\n",
      "loss: 0.230463  [ 3232/17914]\n",
      "loss: 0.208869  [ 6432/17914]\n",
      "loss: 0.094069  [ 9632/17914]\n",
      "loss: 0.070075  [12832/17914]\n",
      "loss: 0.127247  [16032/17914]\n",
      "--------------------------\n",
      "epoch 18/50\n",
      "loss: 0.117865  [   32/17914]\n",
      "loss: 0.225656  [ 3232/17914]\n",
      "loss: 0.151441  [ 6432/17914]\n",
      "loss: 0.082576  [ 9632/17914]\n",
      "loss: 0.043071  [12832/17914]\n",
      "loss: 0.065815  [16032/17914]\n",
      "--------------------------\n",
      "epoch 19/50\n",
      "loss: 0.119945  [   32/17914]\n",
      "loss: 0.146429  [ 3232/17914]\n",
      "loss: 0.120199  [ 6432/17914]\n",
      "loss: 0.016612  [ 9632/17914]\n",
      "loss: 0.056932  [12832/17914]\n",
      "loss: 0.026084  [16032/17914]\n",
      "--------------------------\n",
      "epoch 20/50\n",
      "loss: 0.068264  [   32/17914]\n",
      "loss: 0.109154  [ 3232/17914]\n",
      "loss: 0.102054  [ 6432/17914]\n",
      "loss: 0.026504  [ 9632/17914]\n",
      "loss: 0.111635  [12832/17914]\n",
      "loss: 0.056014  [16032/17914]\n",
      "--------------------------\n",
      "epoch 21/50\n",
      "loss: 0.067976  [   32/17914]\n",
      "loss: 0.122621  [ 3232/17914]\n",
      "loss: 0.039398  [ 6432/17914]\n",
      "loss: 0.014401  [ 9632/17914]\n",
      "loss: 0.021065  [12832/17914]\n",
      "loss: 0.098622  [16032/17914]\n",
      "--------------------------\n",
      "epoch 22/50\n",
      "loss: 0.076294  [   32/17914]\n",
      "loss: 0.082758  [ 3232/17914]\n",
      "loss: 0.068509  [ 6432/17914]\n",
      "loss: 0.008821  [ 9632/17914]\n",
      "loss: 0.008254  [12832/17914]\n",
      "loss: 0.071960  [16032/17914]\n",
      "--------------------------\n",
      "epoch 23/50\n",
      "loss: 0.064846  [   32/17914]\n",
      "loss: 0.051100  [ 3232/17914]\n",
      "loss: 0.007017  [ 6432/17914]\n",
      "loss: 0.092115  [ 9632/17914]\n",
      "loss: 0.005884  [12832/17914]\n",
      "loss: 0.012290  [16032/17914]\n",
      "--------------------------\n",
      "epoch 24/50\n",
      "loss: 0.154981  [   32/17914]\n",
      "loss: 0.033277  [ 3232/17914]\n",
      "loss: 0.018122  [ 6432/17914]\n",
      "loss: 0.044889  [ 9632/17914]\n",
      "loss: 0.027389  [12832/17914]\n",
      "loss: 0.003516  [16032/17914]\n",
      "--------------------------\n",
      "epoch 25/50\n",
      "loss: 0.108357  [   32/17914]\n",
      "loss: 0.052882  [ 3232/17914]\n",
      "loss: 0.087537  [ 6432/17914]\n",
      "loss: 0.023582  [ 9632/17914]\n",
      "loss: 0.003966  [12832/17914]\n",
      "loss: 0.004328  [16032/17914]\n",
      "--------------------------\n",
      "epoch 26/50\n",
      "loss: 0.057727  [   32/17914]\n",
      "loss: 0.024387  [ 3232/17914]\n",
      "loss: 0.016365  [ 6432/17914]\n",
      "loss: 0.007716  [ 9632/17914]\n",
      "loss: 0.002376  [12832/17914]\n",
      "loss: 0.006143  [16032/17914]\n",
      "--------------------------\n",
      "epoch 27/50\n",
      "loss: 0.118394  [   32/17914]\n",
      "loss: 0.035728  [ 3232/17914]\n",
      "loss: 0.002043  [ 6432/17914]\n",
      "loss: 0.009907  [ 9632/17914]\n",
      "loss: 0.092660  [12832/17914]\n",
      "loss: 0.002799  [16032/17914]\n",
      "--------------------------\n",
      "epoch 28/50\n",
      "loss: 0.036251  [   32/17914]\n",
      "loss: 0.032962  [ 3232/17914]\n",
      "loss: 0.009356  [ 6432/17914]\n",
      "loss: 0.002499  [ 9632/17914]\n",
      "loss: 0.001971  [12832/17914]\n",
      "loss: 0.001621  [16032/17914]\n",
      "--------------------------\n",
      "epoch 29/50\n",
      "loss: 0.056271  [   32/17914]\n",
      "loss: 0.016285  [ 3232/17914]\n",
      "loss: 0.008442  [ 6432/17914]\n",
      "loss: 0.004301  [ 9632/17914]\n",
      "loss: 0.025473  [12832/17914]\n",
      "loss: 0.000677  [16032/17914]\n",
      "--------------------------\n",
      "epoch 30/50\n",
      "loss: 0.008867  [   32/17914]\n",
      "loss: 0.022338  [ 3232/17914]\n",
      "loss: 0.002723  [ 6432/17914]\n",
      "loss: 0.063198  [ 9632/17914]\n",
      "loss: 0.000515  [12832/17914]\n",
      "loss: 0.001271  [16032/17914]\n",
      "--------------------------\n",
      "epoch 31/50\n",
      "loss: 0.058814  [   32/17914]\n",
      "loss: 0.004872  [ 3232/17914]\n",
      "loss: 0.000950  [ 6432/17914]\n",
      "loss: 0.017905  [ 9632/17914]\n",
      "loss: 0.006793  [12832/17914]\n",
      "loss: 0.002598  [16032/17914]\n",
      "--------------------------\n",
      "epoch 32/50\n",
      "loss: 0.033950  [   32/17914]\n",
      "loss: 0.010559  [ 3232/17914]\n",
      "loss: 0.004515  [ 6432/17914]\n",
      "loss: 0.039663  [ 9632/17914]\n",
      "loss: 0.001317  [12832/17914]\n",
      "loss: 0.002546  [16032/17914]\n",
      "--------------------------\n",
      "epoch 33/50\n",
      "loss: 0.046573  [   32/17914]\n",
      "loss: 0.027043  [ 3232/17914]\n",
      "loss: 0.000695  [ 6432/17914]\n",
      "loss: 0.022362  [ 9632/17914]\n",
      "loss: 0.000962  [12832/17914]\n",
      "loss: 0.000952  [16032/17914]\n",
      "--------------------------\n",
      "epoch 34/50\n",
      "loss: 0.092234  [   32/17914]\n",
      "loss: 0.026919  [ 3232/17914]\n",
      "loss: 0.002852  [ 6432/17914]\n",
      "loss: 0.001061  [ 9632/17914]\n",
      "loss: 0.254205  [12832/17914]\n",
      "loss: 0.001449  [16032/17914]\n",
      "--------------------------\n",
      "epoch 35/50\n",
      "loss: 0.030195  [   32/17914]\n",
      "loss: 0.038038  [ 3232/17914]\n",
      "loss: 0.004202  [ 6432/17914]\n",
      "loss: 0.000933  [ 9632/17914]\n",
      "loss: 0.001909  [12832/17914]\n",
      "loss: 0.000713  [16032/17914]\n",
      "--------------------------\n",
      "epoch 36/50\n",
      "loss: 0.033575  [   32/17914]\n",
      "loss: 0.006349  [ 3232/17914]\n",
      "loss: 0.073749  [ 6432/17914]\n",
      "loss: 0.000459  [ 9632/17914]\n",
      "loss: 0.000868  [12832/17914]\n",
      "loss: 0.003782  [16032/17914]\n",
      "--------------------------\n",
      "epoch 37/50\n",
      "loss: 0.019969  [   32/17914]\n",
      "loss: 0.003739  [ 3232/17914]\n",
      "loss: 0.002042  [ 6432/17914]\n",
      "loss: 0.002811  [ 9632/17914]\n",
      "loss: 0.004993  [12832/17914]\n",
      "loss: 0.002385  [16032/17914]\n",
      "--------------------------\n",
      "epoch 38/50\n",
      "loss: 0.021533  [   32/17914]\n",
      "loss: 0.019639  [ 3232/17914]\n",
      "loss: 0.007517  [ 6432/17914]\n",
      "loss: 0.000433  [ 9632/17914]\n",
      "loss: 0.006176  [12832/17914]\n",
      "loss: 0.002744  [16032/17914]\n",
      "--------------------------\n",
      "epoch 39/50\n",
      "loss: 0.004533  [   32/17914]\n",
      "loss: 0.116329  [ 3232/17914]\n",
      "loss: 0.011546  [ 6432/17914]\n",
      "loss: 0.038080  [ 9632/17914]\n",
      "loss: 0.000555  [12832/17914]\n",
      "loss: 0.000402  [16032/17914]\n",
      "--------------------------\n",
      "epoch 40/50\n",
      "loss: 0.018743  [   32/17914]\n",
      "loss: 0.014222  [ 3232/17914]\n",
      "loss: 0.019475  [ 6432/17914]\n",
      "loss: 0.000120  [ 9632/17914]\n",
      "loss: 0.000915  [12832/17914]\n",
      "loss: 0.104789  [16032/17914]\n",
      "--------------------------\n",
      "epoch 41/50\n",
      "loss: 0.129940  [   32/17914]\n",
      "loss: 0.013495  [ 3232/17914]\n",
      "loss: 0.000741  [ 6432/17914]\n",
      "loss: 0.001318  [ 9632/17914]\n",
      "loss: 0.001991  [12832/17914]\n",
      "loss: 0.001930  [16032/17914]\n",
      "--------------------------\n",
      "epoch 42/50\n",
      "loss: 0.060147  [   32/17914]\n",
      "loss: 0.031089  [ 3232/17914]\n",
      "loss: 0.000158  [ 6432/17914]\n",
      "loss: 0.096480  [ 9632/17914]\n",
      "loss: 0.013604  [12832/17914]\n",
      "loss: 0.001224  [16032/17914]\n",
      "--------------------------\n",
      "epoch 43/50\n",
      "loss: 0.011498  [   32/17914]\n",
      "loss: 0.043960  [ 3232/17914]\n",
      "loss: 0.033047  [ 6432/17914]\n",
      "loss: 0.008446  [ 9632/17914]\n",
      "loss: 0.012981  [12832/17914]\n",
      "loss: 0.103942  [16032/17914]\n",
      "--------------------------\n",
      "epoch 44/50\n",
      "loss: 0.012905  [   32/17914]\n",
      "loss: 0.006049  [ 3232/17914]\n",
      "loss: 0.000236  [ 6432/17914]\n",
      "loss: 0.006001  [ 9632/17914]\n",
      "loss: 0.007304  [12832/17914]\n",
      "loss: 0.000443  [16032/17914]\n",
      "--------------------------\n",
      "epoch 45/50\n",
      "loss: 0.001857  [   32/17914]\n",
      "loss: 0.001237  [ 3232/17914]\n",
      "loss: 0.001491  [ 6432/17914]\n",
      "loss: 0.000434  [ 9632/17914]\n",
      "loss: 0.000343  [12832/17914]\n",
      "loss: 0.000062  [16032/17914]\n",
      "--------------------------\n",
      "epoch 46/50\n",
      "loss: 0.010946  [   32/17914]\n",
      "loss: 0.002606  [ 3232/17914]\n",
      "loss: 0.000830  [ 6432/17914]\n",
      "loss: 0.000386  [ 9632/17914]\n",
      "loss: 0.000071  [12832/17914]\n",
      "loss: 0.000147  [16032/17914]\n",
      "--------------------------\n",
      "epoch 47/50\n",
      "loss: 0.003788  [   32/17914]\n",
      "loss: 0.001795  [ 3232/17914]\n",
      "loss: 0.004954  [ 6432/17914]\n",
      "loss: 0.001242  [ 9632/17914]\n",
      "loss: 0.001001  [12832/17914]\n",
      "loss: 0.000381  [16032/17914]\n",
      "--------------------------\n",
      "epoch 48/50\n",
      "loss: 0.051988  [   32/17914]\n",
      "loss: 0.000636  [ 3232/17914]\n",
      "loss: 0.000123  [ 6432/17914]\n",
      "loss: 0.001889  [ 9632/17914]\n",
      "loss: 0.002474  [12832/17914]\n",
      "loss: 0.001025  [16032/17914]\n",
      "--------------------------\n",
      "epoch 49/50\n",
      "loss: 0.004411  [   32/17914]\n",
      "loss: 0.006397  [ 3232/17914]\n",
      "loss: 0.000132  [ 6432/17914]\n",
      "loss: 0.000511  [ 9632/17914]\n",
      "loss: 0.004000  [12832/17914]\n",
      "loss: 0.000556  [16032/17914]\n",
      "--------------------------\n",
      "epoch 50/50\n",
      "loss: 0.005833  [   32/17914]\n",
      "loss: 0.016153  [ 3232/17914]\n",
      "loss: 0.001815  [ 6432/17914]\n",
      "loss: 0.009346  [ 9632/17914]\n",
      "loss: 0.002810  [12832/17914]\n",
      "loss: 0.000426  [16032/17914]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "train_loop(train_loader, model, criterion, optimizer, num_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
